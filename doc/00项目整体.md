## 技术架构


## 项目部署

### spark开发阶段部署方式
先部署spark集群，确保mysql、spark启动。
对项目打包，打出spark-uba.jar包。依赖jar包打到lib目录，需要以下两个
```$xslt
fastjson-1.2.31.jar
mysql-connector-java-5.1.46.jar
```
然后编写start.sh，放在lib同级目录，启动脚本即可提交任务到集群。
```
BASEPATH=$(cd `dirname $0`; pwd)
SPARK_BIN=/data/spark-2.1.1-bin-hadoop2.6

executor_memory=4g
master_ip=manager

mkdir -p ${BASEPATH}/logs/

${SPARK_BIN}/bin/spark-submit \
--jars $(echo ${BASEPATH}/lib/*.jar | tr ' ' ',')  \
--class com.stillcoolme.spark.SparkStart  \
--total-executor-cores 6 \
--executor-cores 2 \
--executor-memory $executor_memory \
--master spark://$master_ip:7077  ${BASEPATH}/uba-spark-1.0.0.jar \
>> ${BASEPATH}/logs/spark-uba.log 2>&1
```


spark-env.sh可以配置的参数：
```bash
export JAVA_HOME=
export SPARK_MASTER_IP=
export SPARK_WORKER_MEMORY=64G
export SPARK_DAEMON_MEMORY=2G
export SPARK_HISTORY_OPTS="-Dspark.history.ui.port=7777 -Dspark.history.retainedApplications=3 -Dspark.history.fs.logDirectory=/home/sparkHis"
export SPARK_WORKER_OPTS="  
-Dspark.worker.cleanup.enabled=true  # 是否开启自动清理
-Dspark.worker.cleanup.interval=86400  # 清理周期，每隔多长时间清理一次，单位秒
-Dspark.worker.cleanup.appDataTtl=86400"  # 保留最近多长时间的数据
```
